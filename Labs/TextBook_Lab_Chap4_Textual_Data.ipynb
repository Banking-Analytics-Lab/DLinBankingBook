{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Banking-Analytics-Lab/DLinBankingBook/blob/main/Labs/TextBook_Lab_Chap4_Textual_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy1I2FdzwOiY"
      },
      "source": [
        "# **Transformers for Text Analysis**\n",
        "\n",
        "In this lab, we will explore Transformer models for text analysis using the [Hugging Face Transformers library](https://huggingface.co/docs/transformers/index). This library provides a wide range of pre-trained models that we can leverage for various natural language processing (NLP) tasks.\n",
        "\n",
        "\n",
        "First, we need to install and import the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YupOQrFmVloC"
      },
      "outputs": [],
      "source": [
        "# Install necessasary packages, if not done before\n",
        "!pip install transformers evaluate accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mT4i4wvxgzT"
      },
      "source": [
        "## **Downloading Datasets**\n",
        "\n",
        "Now, we will use two datasets for this lab:\n",
        "\n",
        "1. **Federal Reserve Speeches (1996–2024)**  \n",
        "   - This dataset contains **text data** from speeches delivered by Federal Reserve officials over the years.  \n",
        "\n",
        "2. **[Chicago Fed National Activity Index (CFNAI)](https://fred.stlouisfed.org/series/CFNAI)**  \n",
        "   - The CFNAI is a comprehensive economic indicator that tracks **85 key economic factors** such as employment, production, and consumption.  \n",
        "   - It helps measure national economic activity:\n",
        "     - **Zero value** → Economy is growing at its historical trend rate.\n",
        "     - **Negative values** → Below-average growth.(Economy contracting)\n",
        "     - **Positive values** → Above-average growth.(Economy expanding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak3ZB45npjPp"
      },
      "outputs": [],
      "source": [
        "!gdown --fuzzy 'https://drive.google.com/file/d/1uVt9BC2tgr-MWrFZvYvA_I8IzTabNZtL/view?usp=sharing'\n",
        "!gdown --fuzzy 'https://drive.google.com/file/d/1I7isSks6Y8kJoigbDZJumgdQ1fFpwn4i/view?usp=sharing'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZagDNJVGV5Is"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, auc\n",
        "\n",
        "# Plots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import Image\n",
        "%matplotlib inline\n",
        "\n",
        "# Import Pytorch lybraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "# Huggingface\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import pipeline\n",
        "from transformers import set_seed\n",
        "from datasets import load_dataset, Dataset, Value, ClassLabel, Features, load_from_disk\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBM_h5PgyfSp"
      },
      "source": [
        "Now, we will load the Federal Reserve Speeches dataset.\n",
        "Once loaded, we will inspect the structure of the dataset to understand its key columns, such as date, speaker, speech content, and topic. This will help us determine how to preprocess and analyze the text data effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBzYPaDTyCI2"
      },
      "outputs": [],
      "source": [
        "fed_speech = pd.read_csv(\"/content/fed_speeches.csv\", delimiter=\",\", on_bad_lines=\"skip\", engine=\"python\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqL4mDPWyMUB"
      },
      "outputs": [],
      "source": [
        "fed_speech.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ylb8nURySKh"
      },
      "outputs": [],
      "source": [
        "fed_speech.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL3CZSjKzjKk"
      },
      "source": [
        "## Data preprocess - merging\n",
        "\n",
        "In this step, we will preprocess the Federal Reserve Speeches dataset to prepare it for analysis. First, we will extract the **year** and **month** from the speech dates. Then, we will shift the month forward by one to align each speech with the economic conditions of the following month.\n",
        "\n",
        "Our goal is to predict the next month's economic upturn or downturn based on the language used in Federal Reserve speeches. This adjustment ensures that our model learns from past speeches to forecast future economic trends more effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdCcXGTAjhvc"
      },
      "outputs": [],
      "source": [
        "# Create year and month columns\n",
        "fed_speech['date'] = pd.to_datetime(fed_speech['date'], errors='coerce')\n",
        "fed_speech[\"year\"] = fed_speech[\"date\"].dt.year  # Extract year\n",
        "fed_speech[\"month\"] = fed_speech[\"date\"].dt.month  # Extract month\n",
        "\n",
        "# Shift df1's month forward by 1\n",
        "fed_speech[\"month\"] += 1\n",
        "\n",
        "# Handle December (12 → 1 and increase year)\n",
        "fed_speech.loc[fed_speech[\"month\"] == 13, \"month\"] = 1\n",
        "fed_speech.loc[fed_speech[\"month\"] == 1, \"year\"] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8JIsW4A0aWK"
      },
      "source": [
        "Next, we will load the Chicago Fed National Activity Index (CFNAI) dataset, which serves as a key indicator of U.S. economic activity.\n",
        "\n",
        "Once loaded, we will merge the CFNAI dataset with the Federal Reserve Speeches dataset using year and month as the merging keys. Since we previously adjusted the speech dataset by shifting the month forward, this ensures that each speech is aligned with the economic activity of the following month."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwaT9MI3hzfR"
      },
      "outputs": [],
      "source": [
        "econ_index = pd.read_csv('/content/CFNAI.csv')\n",
        "econ_index.columns = ['date', 'CFNAI']\n",
        "econ_index['date'] = pd.to_datetime(econ_index['date'], errors='coerce')\n",
        "econ_index[\"year\"] = econ_index[\"date\"].dt.year  # Extract year\n",
        "econ_index[\"month\"] = econ_index[\"date\"].dt.month  # Extract month\n",
        "econ_index.drop(columns=['date'], inplace=True)\n",
        "econ_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unfhCa1yiJYY"
      },
      "outputs": [],
      "source": [
        "merged_df = fed_speech.merge(econ_index, on=[\"year\", \"month\"], how=\"left\")\n",
        "merged_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMf_oFsW0yi0"
      },
      "source": [
        "## **Text Preprocessing: Tokenization, Stopword Removal, and Cleaning**\n",
        "\n",
        "In this step, we preprocess the speech text by **tokenizing, removing stopwords, and eliminating punctuation** to prepare the data for further analysis.\n",
        "\n",
        "### **1. Import Required Libraries**\n",
        "The following libraries from **NLTK (Natural Language Toolkit)** are used:\n",
        "- `word_tokenize` → Splits text into individual words (tokens).\n",
        "- `stopwords` → Provides a list of common English stopwords (e.g., \"the\", \"is\", \"and\").\n",
        "- `string` → Used to remove punctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHugYOIU_8VD"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    tokens = word_tokenize(text)  # Tokenize text\n",
        "    table = str.maketrans('', '', string.punctuation)  # Create a table for removing punctuation\n",
        "    filtered_tokens = [\n",
        "        token.translate(table) for token in tokens\n",
        "        if token.isalnum() and token not in stop_words  # Remove stop words here!\n",
        "    ]\n",
        "    cleaned_text = ' '.join(filtered_tokens)\n",
        "    return cleaned_text\n",
        "\n",
        "merged_df['text_cleaned'] = merged_df['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QXGnVorvImy"
      },
      "source": [
        "As we discuss in the book, you would need to test the best performance depending on the cleaning steps necessary. Normally, either doing nothing, removing stopwords, or lowercase would lead to the best performance depending on the application area. Combining strategies may lead to decreased performance. Test different strategies and see if you can improve this model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW_a3wdk1nxz"
      },
      "source": [
        "You can inspect how the **`clean_text`** function processed the text by viewing the cleaned version stored in the **`text_cleaned`** column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iU2dUBOpAfpq"
      },
      "outputs": [],
      "source": [
        "merged_df.tail(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzPc75EP2L99"
      },
      "source": [
        "As observed above, rows corresponding to **January 2025 (2025-01)** do not have CFNAI values. To address this, we will extract these rows and set them aside for testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D5JdZoFtaj9"
      },
      "outputs": [],
      "source": [
        "# Extract the last two rows that contain NaN values\n",
        "nan_rows_df = merged_df[merged_df.isna().any(axis=1)]\n",
        "\n",
        "# Remove these rows from the main DataFrame\n",
        "merged_df = merged_df.drop(nan_rows_df.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ7WvL9K2nsv"
      },
      "source": [
        "## **Visualizing Frequent Words in FED Speeches with a Word Cloud**  \n",
        "\n",
        "In this step, we generate a **word cloud** to visualize the most frequently used words in the **Federal Reserve speeches dataset**. A word cloud is a useful tool for quickly identifying common terms in text data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_vMZikiBQY6"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "sample_txt = \" \".join(i for i in merged_df['text_cleaned'])\n",
        "\n",
        "wc = WordCloud(colormap=\"Set2\",collocations=False).generate(sample_txt)\n",
        "plt.title(\"Most Frequent Words in FED Speeches\")\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(wc,interpolation='bilinear')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBXRAU_Y25rF"
      },
      "source": [
        "Pretty cool! We can see that the Federal Reserve frequently uses words like risk, inflation, and financial, among others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN8NjsHt3OXf"
      },
      "source": [
        "## Labelling\n",
        "\n",
        "In this step, we categorize the **Chicago Fed National Activity Index (CFNAI)** values into binary labels to prepare our dataset for classification.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Define Bins and Labels**  \n",
        "We create two categories based on the CFNAI values:  \n",
        "- **Negative or zero CFNAI (`≤ 0`) → Label 1**  \n",
        "- **Positive CFNAI (`> 0`) → Label 0**  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ksNh1VUEc3G"
      },
      "outputs": [],
      "source": [
        "# Define bins and labels\n",
        "bins = [-float('inf'), 0, float('inf')]\n",
        "labels = [1, 0]\n",
        "\n",
        "# Apply categorization\n",
        "merged_df[\"label\"] = pd.cut(\n",
        "    merged_df[\"CFNAI\"], bins=bins, labels=labels, include_lowest=True\n",
        ")\n",
        "\n",
        "# Convert to integer type\n",
        "merged_df[\"label\"] = merged_df[\"label\"].astype(int)\n",
        "\n",
        "merged_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFQW7Ebs3p-8"
      },
      "source": [
        "We can see that the labels are fairly balanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsehhXDDHEZE"
      },
      "outputs": [],
      "source": [
        "merged_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NazCyb73y8P"
      },
      "source": [
        "Now that we have cleaned and processed the dataset, we will save it for future use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5V_VcrZWHkl"
      },
      "outputs": [],
      "source": [
        "# Save to CSV\n",
        "merged_df.to_csv('FEDSpeechesProcessed.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtx62uNB3_Cc"
      },
      "source": [
        "## **Preparing the Dataset for Model Training**  \n",
        "\n",
        "In this step, we **convert the preprocessed dataset into a Hugging Face `Dataset` format**, encode the labels, and split the data into training and testing sets.\n",
        "\n",
        "---\n",
        "\n",
        "We extract the **cleaned text (`text_cleaned`)** and its corresponding **label (`label`)** from `merged_df`, then convert it into a Hugging Face `Dataset`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mojsQl6-WJ3z"
      },
      "outputs": [],
      "source": [
        "# Create the dataset\n",
        "fed_speech_data = Dataset.from_pandas(merged_df.loc[:,['text_cleaned', 'label']])\n",
        "\n",
        "# Set the label variable\n",
        "fed_speech_data = fed_speech_data.class_encode_column(\"label\")\n",
        "\n",
        "# Drop the index variable\n",
        "fed_speech_data = fed_speech_data.remove_columns([\"__index_level_0__\"])\n",
        "\n",
        "# Train / test split\n",
        "fed_speech_data = fed_speech_data.train_test_split(0.33)\n",
        "fed_speech_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZriKlSJ0WLZw"
      },
      "outputs": [],
      "source": [
        "fed_speech_data['train'].features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qqh4dpj4U_h"
      },
      "source": [
        "## **Tokenizing the Text Data**  \n",
        "\n",
        "Before feeding our text data into a Transformer model, we need to **tokenize** it. Tokenization converts raw text into numerical format that the model can understand.\n",
        "\n",
        "---\n",
        "\n",
        "We use the **DistilBERT tokenizer** from Hugging Face’s `transformers` library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OMYzNC4WMry"
      },
      "outputs": [],
      "source": [
        "# Tokenize the data.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\",  do_lower_case=False, processing_class=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3AriIpwWOIY"
      },
      "outputs": [],
      "source": [
        "# Function to truncate text. Our text is very long!\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text_cleaned\"], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yfa0Vs4WPR2"
      },
      "outputs": [],
      "source": [
        "tokenized_fed_speech_data = fed_speech_data.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f9dsOFvWQ3O"
      },
      "outputs": [],
      "source": [
        "# Save the outcome to disk to not run this again.\n",
        "tokenized_fed_speech_data.save_to_disk(\"TokenizedData\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGRFUQtE4k6-"
      },
      "source": [
        "## **Applying Data Collation for Efficient Batching**  \n",
        "\n",
        "When working with Transformer models, input sequences need to be **padded** to the same length within a batch. To handle this efficiently, we use a **data collator**.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qu4WZMwvWR-8"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo_Jt2paWUQh"
      },
      "outputs": [],
      "source": [
        "# How many classes there are.\n",
        "num_labels = len(merged_df[\"label\"].unique())\n",
        "print(f'There are {num_labels} classes in the dataset.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3w6fZ1G4xp5"
      },
      "source": [
        "Now that we have tokenized the text data, we need to define the **Transformer model** that will be used for classification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKAACTIKWVoC"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\", num_labels=num_labels\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iafJYEwy4-Lv"
      },
      "source": [
        "We define the **evaluation metric** to assess the performance of our model. We use **accuracy**, which measures the proportion of correctly classified samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6slGEvdWXLM"
      },
      "outputs": [],
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJIptmcv5FIs"
      },
      "source": [
        "## **Defining Training Parameters**  \n",
        "\n",
        "Now, we configure the **training arguments** that determine how our model will be trained using the Hugging Face `Trainer` API.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2r8eCt0WY81"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    # Where to store the model.\n",
        "  output_dir=\"ModelOutput\",\n",
        "    # Learning rate to use.\n",
        "    learning_rate=1e-4,\n",
        "    # Batch size to use per GPU in training.\n",
        "    #per_device_train_batch_size=32,  ## T4\n",
        "    per_device_train_batch_size=200,  ## T4\n",
        "    # Batch size to use per GPU in evaluation\n",
        "    #per_device_eval_batch_size=32,   ## T4\n",
        "    per_device_eval_batch_size=200,  ## T4\n",
        "    # Epochs to train\n",
        "    num_train_epochs=15,\n",
        "    # If decaying or not the weights\n",
        "    weight_decay=5e-3,\n",
        "    # When to evaluate the model\n",
        "    eval_strategy=\"epoch\",\n",
        "    # When to save checkpoint\n",
        "    save_strategy=\"epoch\",\n",
        "    # Load best after training? No as we don't have validation / test difference.\n",
        "    load_best_model_at_end=False,\n",
        "    # Save in Huggingface? (Account required)\n",
        "    push_to_hub=False,\n",
        "    # How often to log training\n",
        "    logging_steps=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf0HCg9l5QDK"
      },
      "source": [
        "We **set a fixed random seed** for reproducibility and initialize the Hugging Face `Trainer` for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VMLZjL0gMt_"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LnX3LKqWbLO"
      },
      "outputs": [],
      "source": [
        "# Set a fixed seed value\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "transformers.set_seed(SEED)\n",
        "\n",
        "# Empty VRAM\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Create trainer object.\n",
        "trainer = Trainer(\n",
        "    # What model to use.\n",
        "    model=model,\n",
        "    # Arguments to the model\n",
        "    args=training_args,\n",
        "    # Training data\n",
        "    train_dataset=tokenized_fed_speech_data[\"train\"],\n",
        "    # Test dataset\n",
        "    eval_dataset=tokenized_fed_speech_data[\"test\"],\n",
        "    # How to pad sequences\n",
        "    data_collator=data_collator,\n",
        "    # Error function\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtOW5Vw05Urb"
      },
      "source": [
        "Now that we have set up the **dataset, tokenizer, model, training arguments, and `Trainer`**, it's time to **train the model**!  \n",
        "\n",
        "To enable experiment tracking, we will use **Weights & Biases (W&B)** for logging training metrics. Before training, you need to sign in to [wandb.ai](https://wandb.ai/home) to get an API key.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwQlF3BpWdYr"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN3d1NLo65qg"
      },
      "source": [
        "We can see that the **accuracy is increasing** as training progresses, indicating that the model is learning from the data.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1otCKKq62Ex"
      },
      "source": [
        "After training, we need to **save the model** so we can reuse it for evaluation, inference, or further fine-tuning without retraining from scratch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Fra8wgyWe18"
      },
      "outputs": [],
      "source": [
        "# Save the model to a folder\n",
        "trainer.save_model('FEDSppechModel')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJEllKOGWfIl"
      },
      "outputs": [],
      "source": [
        "# Zip it\n",
        "!zip -r DistilBert.zip FEDSppechModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAF_H1tgpzgS"
      },
      "outputs": [],
      "source": [
        "# Calculate AUC over the test set.\n",
        "predictions = trainer.predict(tokenized_fed_speech_data[\"test\"])\n",
        "preds = predictions.predictions\n",
        "preds\n",
        "\n",
        "# Plot ROC Curve\n",
        "fpr, tpr, threshold = roc_curve(tokenized_fed_speech_data[\"test\"][\"label\"], preds[:, 1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.savefig('c3_ROC_Curve.pdf')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_XvRiN56724"
      },
      "source": [
        "## **Testing the Model on Recent FED Speeches**  \n",
        "\n",
        "Now that we have trained our model, let's test it on **recent Federal Reserve speeches** to evaluate its performance in predicting economic sentiment.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crp5AfajWjyJ"
      },
      "outputs": [],
      "source": [
        "text = nan_rows_df.iloc[0]['text_cleaned']\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vi9L9JTgWlKP"
      },
      "outputs": [],
      "source": [
        "# Apply tokenizer and return pytorch tensors\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ice3geSgWnX0"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(**inputs.to(\"cuda\"))\n",
        "    logits = outputs.logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZ5EdLsuWo5k"
      },
      "outputs": [],
      "source": [
        "# Probabilities\n",
        "probs = nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
        "print(probs)\n",
        "\n",
        "# Class\n",
        "print(f'The text is predicted to be of class {np.argmax(probs)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0gq76E57n-S"
      },
      "source": [
        "Our model predicts an economic downturn in January 2025 based on Federal Reserve speeches from December 2024.\n",
        "\n",
        "And the CFNAI for January 2025 is [-0.03](https://fred.stlouisfed.org/series/CFNAI), which is classified as econnomic downturn in our analysis!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y65v6nRjQMW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQDPZJZsjWhQ"
      },
      "outputs": [],
      "source": [
        "# Move the best model to drive\n",
        "!cp DistilBert.zip '/content/drive/MyDrive/Colab Notebooks/DL in Banking Book/DeepLearningInBankingBook/TextBook_Lab'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}