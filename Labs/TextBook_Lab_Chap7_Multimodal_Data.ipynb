{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7SVPKJMGngm"
   },
   "source": [
    "# Multimodal Model – Combining Time-Series, Static Variables, Images, and Text\n",
    "\n",
    "In this lab, we will explore multimodal models that integrate time-series data, static variables, images, and text, leveraging all the datasets we have used previously.\n",
    "\n",
    "First, we need to install and import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEZ2bVVh20vc"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "bookPath = '/content/drive/MyDrive/Colab Notebooks/DL in Banking Book/DeepLearningInBankingBook/TextBook_Lab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1746543087337,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "vbQk9uXd6Rzb"
   },
   "outputs": [],
   "source": [
    "bookPath = '/content/drive/MyDrive/Colab Notebooks/DL in Banking Book/DeepLearningInBankingBook/TextBook_Lab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 75881,
     "status": "ok",
     "timestamp": 1746540119395,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "ooXxYW4mz0yB",
    "outputId": "ffe41306-1917-4f71-f73f-f50062d5c10d"
   },
   "outputs": [],
   "source": [
    "# Install necessasary packages, if not done before\n",
    "!pip install transformers evaluate accelerate hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8949,
     "status": "ok",
     "timestamp": 1746540151589,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "r8noMvsoz9nO"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "\n",
    "# Import Pytorch lybraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "# Huggingface\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "from transformers import set_seed\n",
    "from datasets import load_dataset, Dataset, Value, ClassLabel, Features, load_from_disk\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIm_Hc3HHLNp"
   },
   "source": [
    "## Cleaning Time Series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2_YrOWsHOnQ"
   },
   "source": [
    "Let's start by downloading the time-series dataset from Freddie Mac. This dataset provides monthly loan status updates covering the period from November 2021 to June 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8421,
     "status": "ok",
     "timestamp": 1746540160012,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "MMPoPT88z_9N",
    "outputId": "63bf99f4-2a81-4ea1-ca1c-96efedf68c2d"
   },
   "outputs": [],
   "source": [
    "!gdown --fuzzy 'https://drive.google.com/file/d/1cte8MKaSdt3LrqXSUo9oGTe2hnkz8JsU/view?usp=sharing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 1802,
     "status": "ok",
     "timestamp": 1746540161817,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "HdaeW87H0JVx",
    "outputId": "10ae8d6f-038d-46c6-a334-ece60e20ed32"
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('Multimodal_Lab_sampled.csv', low_memory=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeAt3DudHh1R"
   },
   "source": [
    "We assign a value of 1 to loans that were delinquent at least once in the last three months (April to June 2024). Our goal is to predict whether a loan will become delinquent in the next quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 19834,
     "status": "ok",
     "timestamp": 1746540181653,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "-MgjEI8G0Qwp",
    "outputId": "ea6aedfa-dd7d-41e6-ad09-af9e39259408"
   },
   "outputs": [],
   "source": [
    "# Convert REPORTING_PERIOD to datetime for sorting\n",
    "df[\"REPORTING_PERIOD\"] = pd.to_datetime(df[\"REPORTING_PERIOD\"], format='%Y%m')\n",
    "\n",
    "df[\"CURRENT_LOAN_DELINQUENCY_STATUS\"] = pd.to_numeric(df[\"CURRENT_LOAN_DELINQUENCY_STATUS\"], errors='coerce').fillna(1)\n",
    "\n",
    "# Sort data by Loan Number and Reporting Period (chronological order)\n",
    "df = df.sort_values(by=[\"LOAN_NUMBER\", \"REPORTING_PERIOD\"])\n",
    "\n",
    "\n",
    "# Identify loans that were delinquent at least once in the period 2024-04 to 2024-06\n",
    "df[\"CURRENT_LOAN_DELINQUENCY_STATUS\"] = (df[\"CURRENT_LOAN_DELINQUENCY_STATUS\"] > 0).astype(int)\n",
    "mask = (df[\"REPORTING_PERIOD\"] >= \"2024-04-01\") & (df[\"REPORTING_PERIOD\"] <= \"2024-06-30\")\n",
    "df[\"target\"] = df.groupby(\"LOAN_NUMBER\")[\"CURRENT_LOAN_DELINQUENCY_STATUS\"].transform(lambda x: x[mask].max()).astype(int)\n",
    "\n",
    "\n",
    "# Remove the last three months (April 2024 - June 2024)\n",
    "df = df[~df[\"REPORTING_PERIOD\"].between(pd.Timestamp(\"2024-03-31\"), pd.Timestamp(\"2024-06-02\"))]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0nAKApNIKY-"
   },
   "source": [
    "We normalize the data and One Hot Encode the labels using sklearn's OneHotEncode function. We will also set the class weights as we have done before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 29422,
     "status": "ok",
     "timestamp": 1746540211089,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "LouB_3rf0dXz"
   },
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    \"CURRENT_ACTUAL_UPB\",\n",
    "    \"LOAN_AGE\",\n",
    "    \"REMAINING_MONTHS\",\n",
    "    \"CURRENT_INTEREST_RATE\",\n",
    "    \"CURRENT_NON_INTEREST_BEARING_UPB\",\n",
    "    \"ESTIMATED_LOAN_TO_VALUE\",\n",
    "    \"INTEREST_BEARING_UPB\",\n",
    "    \"CURRENT_LOAN_DELINQUENCY_STATUS\"\n",
    "]\n",
    "\n",
    "# Group by loan number for sequence creation\n",
    "grouped = df.groupby(\"LOAN_NUMBER\")\n",
    "\n",
    "# Store sequences and targets\n",
    "X_dict = {}\n",
    "y_dict = {}\n",
    "\n",
    "for loan_id, group in grouped:\n",
    "    group = group.sort_values(\"REPORTING_PERIOD\")  # Sort each loan's time series\n",
    "\n",
    "    # Extract features as separate sequences\n",
    "    X_dict[loan_id] = {col: group[col].values for col in num_cols}\n",
    "\n",
    "    # Assign existing target value (no need to recalculate)\n",
    "    y_dict[loan_id] = group[\"target\"].iloc[0]\n",
    "\n",
    "\n",
    "\n",
    "# Perform stratified split\n",
    "# Convert dictionary to DataFrame\n",
    "np.random.seed(42)\n",
    "x_df = pd.DataFrame.from_dict(X_dict, orient=\"index\")\n",
    "\n",
    "# Map target values from y_dict\n",
    "x_df[\"target\"] = x_df.index.map(y_dict)\n",
    "\n",
    "# Perform stratified split\n",
    "train_idx, test_idx = train_test_split(\n",
    "    x_df.index, test_size=0.2, stratify=x_df[\"target\"], random_state=42\n",
    ")\n",
    "\n",
    "# Assign 'if_test' column based on stratified split\n",
    "x_df[\"if_test\"] = 0  # Default to training\n",
    "x_df.loc[test_idx, \"if_test\"] = 1  # Mark test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3528,
     "status": "ok",
     "timestamp": 1746540214633,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "48J6inbz0fwJ"
   },
   "outputs": [],
   "source": [
    "# Function to scale each feature separately\n",
    "def scale_dataframe_sequences(x_df, test_var=None):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Split data into train and test\n",
    "    if test_var is not None:\n",
    "        x_train = x_df.loc[test_var == 0, :]\n",
    "        x_test = x_df.loc[test_var == 1, :]\n",
    "    else:\n",
    "        x_train = x_df\n",
    "\n",
    "    scaled_data = {}\n",
    "    scaled_data_test = {}\n",
    "\n",
    "    # Get sequence length from first row\n",
    "    seq_len = len(next(iter(x_train.iloc[0])))\n",
    "\n",
    "    for column in num_cols:\n",
    "        # Stack time series data for each loan into a 2D array\n",
    "        data = np.stack(x_train[column].values).reshape(-1, seq_len)\n",
    "        if column != \"CURRENT_LOAN_DELINQUENCY_STATUS\":\n",
    "          scaled_data[column] = scaler.fit_transform(data).reshape(-1, 1, seq_len).tolist()\n",
    "        else:\n",
    "          scaled_data[column] = data.reshape(-1, 1, seq_len).tolist()\n",
    "\n",
    "        # Scale test set if provided\n",
    "        if test_var is not None:\n",
    "            data_test = np.stack(x_test[column].values).reshape(-1, seq_len)\n",
    "            if column != \"CURRENT_LOAN_DELINQUENCY_STATUS\":\n",
    "              scaled_data_test[column] = scaler.transform(data_test).reshape(-1, 1, seq_len).tolist()\n",
    "            else:\n",
    "              scaled_data_test[column] = data_test.reshape(-1, 1, seq_len).tolist()\n",
    "\n",
    "    # Create new DataFrames with scaled data\n",
    "    scaled_df = pd.DataFrame(scaled_data)\n",
    "    scaled_df = scaled_df.map(lambda x: np.array(x[0]))\n",
    "\n",
    "    if test_var is not None:\n",
    "        scaled_df_test = pd.DataFrame(scaled_data_test)\n",
    "        scaled_df_test = scaled_df_test.map(lambda x: np.array(x[0]))\n",
    "        return scaled_df, scaled_df_test\n",
    "    else:\n",
    "        return scaled_df, _\n",
    "\n",
    "# Normalize train and test sets\n",
    "x_train_val, x_test = scale_dataframe_sequences(x_df[num_cols], x_df[\"if_test\"])\n",
    "\n",
    "# One-hot encode the target variable\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "y_train_val = enc.fit_transform(x_df.loc[x_df[\"if_test\"] == 0, \"target\"].values.reshape(-1, 1))[:, 1]\n",
    "y_test = enc.transform(x_df.loc[x_df[\"if_test\"] == 1, \"target\"].values.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# Compute class weights\n",
    "pos_weight = np.sum(1 - y_train_val) / np.sum(y_train_val)\n",
    "pos_weight = torch.tensor(pos_weight, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1746540214724,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "YM-25SbNtQpH",
    "outputId": "f583650a-e4f4-47f6-f371-849225763606"
   },
   "outputs": [],
   "source": [
    "x_train_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fx4c1KjnIFE6"
   },
   "source": [
    "## Cleaning static variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8xSwF39ITWt"
   },
   "source": [
    "Next, we will clean static features such as credit score, property type, and occupancy status, which were recorded at the time of the loan application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4674,
     "status": "ok",
     "timestamp": 1746540219435,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "VQfQ5xznHYaT",
    "outputId": "5de9b815-89d3-483a-e394-bf232364edf0"
   },
   "outputs": [],
   "source": [
    "!gdown --fuzzy 'https://drive.google.com/file/d/1lF1n0Ue-emaflJabOfmQI6CT0D3qAIYK/view?usp=sharing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1746540219621,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "Z6_C2v1eFf40",
    "outputId": "ce639f0b-dd11-45f1-979e-c76f9d946aa6"
   },
   "outputs": [],
   "source": [
    "# Load filtered static dataset\n",
    "static_df = pd.read_csv(\"Multimodal_Lab_Origin_sampled.csv\", dtype=str)\n",
    "static_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwGmgYJkI0ZK"
   },
   "source": [
    "We normalize numeric variables and one-hot encode categorical variables to ensure consistency in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1746540219652,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "8H2gSmKE0noL"
   },
   "outputs": [],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_cols = [\"CREDIT_SCORE\", \"CLTV\", \"DTI_RATIO\", \"ORIGINAL_UPB\", \"ORIGINAL_LOAN_TERM\", \"MI_PERCENTAGE\"]  # Excluding \"NUMBER_OF_BORROWERS\"\n",
    "categorical_cols = [\"FIRST_TIME_HOMEBUYER\", \"OCCUPANCY_STATUS\", \"PROPERTY_TYPE\"]\n",
    "\n",
    "\n",
    "static_df[\"ZIP3\"] = static_df[\"ZIP3\"].astype(str).str[:-2]\n",
    "static_df[numeric_cols] = static_df[numeric_cols].astype(float)\n",
    "static_df[\"NUMBER_OF_BORROWERS\"] = static_df[\"NUMBER_OF_BORROWERS\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1746540219771,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "Mk8EyWAL0wxx",
    "outputId": "4ce43aa1-497f-457a-abd5-fb387c35b09e"
   },
   "outputs": [],
   "source": [
    "# Add LOAN_NUMBER back before merging\n",
    "x_df[\"LOAN_NUMBER\"] = x_df.index  # Assign index (loan numbers) back to x_df\n",
    "\n",
    "# Assign LOAN_NUMBER to train and test sets\n",
    "loan_numbers_train = x_df.loc[x_df[\"if_test\"] == 0, \"LOAN_NUMBER\"]\n",
    "loan_numbers_test = x_df.loc[x_df[\"if_test\"] == 1, \"LOAN_NUMBER\"]\n",
    "\n",
    "# Split static data into train and test based on LOAN_NUMBER\n",
    "static_train_val = static_df[static_df[\"LOAN_NUMBER\"].isin(loan_numbers_train)]\n",
    "static_test = static_df[static_df[\"LOAN_NUMBER\"].isin(loan_numbers_test)]\n",
    "\n",
    "# --- SCALE NUMERIC FEATURES ---\n",
    "scaler = StandardScaler()\n",
    "static_train_val[numeric_cols] = scaler.fit_transform(static_train_val[numeric_cols])  # Fit on train\n",
    "static_test[numeric_cols] = scaler.transform(static_test[numeric_cols])  # Apply to test\n",
    "\n",
    "# --- ONE-HOT ENCODE CATEGORICAL FEATURES ---\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "encoded_train = encoder.fit_transform(static_train_val[categorical_cols])  # Fit on train\n",
    "encoded_test = encoder.transform(static_test[categorical_cols])  # Apply to test\n",
    "\n",
    "# Convert to DataFrame\n",
    "encoded_train_df = pd.DataFrame(encoded_train, columns=encoder.get_feature_names_out(categorical_cols), index=static_train_val.index)\n",
    "encoded_test_df = pd.DataFrame(encoded_test, columns=encoder.get_feature_names_out(categorical_cols), index=static_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Owxo02fnJHIP"
   },
   "source": [
    "We then merge the cleaned static variables with the time-series table to create a unified dataset for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1746540219780,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "oUXcHmWlJI9F",
    "outputId": "820b448c-bf43-4fcf-e3c9-823b29c0b6ac"
   },
   "outputs": [],
   "source": [
    "# Preserve LOAN_NUMBER and NUMBER_OF_BORROWERS (without scaling)\n",
    "static_train_final = pd.concat([\n",
    "    static_train_val[[\"LOAN_NUMBER\", \"NUMBER_OF_BORROWERS\",\"MSA\",\"ZIP3\"]],  # Keep unscaled\n",
    "    static_train_val[numeric_cols],  # Already scaled numeric features\n",
    "    encoded_train_df  # One-hot encoded categorical features\n",
    "], axis=1)\n",
    "\n",
    "static_test_final = pd.concat([\n",
    "    static_test[[\"LOAN_NUMBER\", \"NUMBER_OF_BORROWERS\",\"MSA\",\"ZIP3\"]],  # Keep unscaled\n",
    "    static_test[numeric_cols],  # Already scaled numeric features\n",
    "    encoded_test_df  # One-hot encoded categorical features\n",
    "], axis=1)\n",
    "\n",
    "print(f\"Processed Train Static Data Shape: {static_train_final.shape}\")\n",
    "print(f\"Processed Test Static Data Shape: {static_test_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1746540219837,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "KczXkFb6JMeB",
    "outputId": "e46a5d04-be8f-4918-b6ab-735f963754f2"
   },
   "outputs": [],
   "source": [
    "# Convert index to DataFrame to allow merging\n",
    "x_train_val = x_train_val.copy()\n",
    "x_test = x_test.copy()\n",
    "\n",
    "# Add LOAN_NUMBER column before merging\n",
    "x_train_val[\"LOAN_NUMBER\"] = loan_numbers_train.values\n",
    "x_test[\"LOAN_NUMBER\"] = loan_numbers_test.values\n",
    "\n",
    "# Merge static data with LSTM sequences\n",
    "x_train_val = x_train_val.merge(static_train_final, on=\"LOAN_NUMBER\", how=\"left\")\n",
    "x_test = x_test.merge(static_test_final, on=\"LOAN_NUMBER\", how=\"left\")\n",
    "\n",
    "# Drop LOAN_NUMBER after merging\n",
    "x_train_val.drop(columns=[\"LOAN_NUMBER\"], inplace=True)\n",
    "x_test.drop(columns=[\"LOAN_NUMBER\"], inplace=True)\n",
    "\n",
    "print(f\"x_train Shape After Merge: {x_train_val.shape}\")\n",
    "print(f\"x_test Shape After Merge: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qitwMLL0JfFt"
   },
   "source": [
    "## Merging image dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZspr8x3Ja60"
   },
   "source": [
    "Next, we will merge the image mapping dataset using MSA (Metropolitan Statistical Area) and ZIP3 (the first three digits of the ZIP code) to align LiDAR images with the corresponding loan records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5687,
     "status": "ok",
     "timestamp": 1746540225553,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "469Bo8tOF5Q0",
    "outputId": "e39e937f-c30c-4718-80aa-9b8fc778d059"
   },
   "outputs": [],
   "source": [
    "!gdown --fuzzy 'https://drive.google.com/file/d/1cHLNcnTLdaKtedM_Uz-xmYaXXml0Ws-D/view?usp=sharing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 614,
     "status": "ok",
     "timestamp": 1746540226170,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "xuKbt2dWF8GB",
    "outputId": "876b9db8-57cb-4508-84e1-f4be9b13b245"
   },
   "outputs": [],
   "source": [
    "!unzip usgs_lidar.zip -d usgs_lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4414,
     "status": "ok",
     "timestamp": 1746540230586,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "jme-QaAZIMzP",
    "outputId": "5a5c2d2c-a2e3-4e50-fce4-e3d5c9017a5a"
   },
   "outputs": [],
   "source": [
    "!gdown --fuzzy 'https://drive.google.com/file/d/1QyzNtHVurvrXvHG1j2oeq7rwfC6vnA1h/view?usp=sharing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1746540230636,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "LcOTi3XOGTIq",
    "outputId": "f0fa89b2-195c-4016-96e0-d1cc7c5df454"
   },
   "outputs": [],
   "source": [
    "image_df = pd.read_csv('msa_zip3_mapping_cleaned.csv', dtype=str)\n",
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1746540230665,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "_1FdtpyfIIEt"
   },
   "outputs": [],
   "source": [
    "# Merge static data with LSTM sequences\n",
    "x_train_val = x_train_val.merge(image_df, on=[\"MSA\",\"ZIP3\"], how=\"left\")\n",
    "x_test = x_test.merge(image_df, on=[\"MSA\",\"ZIP3\"], how=\"left\")\n",
    "\n",
    "# Drop LOAN_NUMBER after merging\n",
    "x_train_val.drop(columns=[\"MSA\", \"ZIP3\"], inplace=True)\n",
    "x_test.drop(columns=[\"MSA\", \"ZIP3\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewv5YhQ7JxNf"
   },
   "source": [
    "Finally, we have established a comprehensive dataset that integrates time-series data, static variables, and image mapping, providing a unified foundation for our multimodal analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1746540230793,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "kqxvSmd3cb3Z",
    "outputId": "1bf3d5e7-933c-4d91-e540-0f3fdfc18531"
   },
   "outputs": [],
   "source": [
    "x_train_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMXV1p_clNIR"
   },
   "source": [
    "##  Get fixed textual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qELKhCT8KUIa"
   },
   "source": [
    "We will use the most recent Federal Reserve speech from March 2024 as the fixed textual data for our analysis.\n",
    "\n",
    "**Scenario**:\n",
    "\n",
    "You are a data scientist at a bank, analyzing loan risk. After watching the Federal Reserve speech from March 2024, you aim to leverage multiple datasets—including time-series data from the loan dataset, static features from loan applications, LiDAR images, and the FED speech—to predict whether a loan will become delinquent in the next quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6909,
     "status": "ok",
     "timestamp": 1746540237704,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "fcf9UzgSfs9j",
    "outputId": "04db3df7-cc3d-4659-9c4d-07413fde44ca"
   },
   "outputs": [],
   "source": [
    "!gdown --fuzzy 'https://drive.google.com/file/d/1uVt9BC2tgr-MWrFZvYvA_I8IzTabNZtL/view?usp=sharing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1746540238293,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "n8Ll-LLukH3w"
   },
   "outputs": [],
   "source": [
    "fed_speech = pd.read_csv(\"/content/fed_speeches.csv\", delimiter=\",\", on_bad_lines=\"skip\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 488,
     "status": "ok",
     "timestamp": 1746540238783,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "ORNWnIFZkKt5",
    "outputId": "414abb2d-7d94-4aca-e606-3a75bed7850c"
   },
   "outputs": [],
   "source": [
    "# Create year and month columns\n",
    "fed_speech['date'] = pd.to_datetime(fed_speech['date'], errors='coerce')\n",
    "fed_speech[\"year\"] = fed_speech[\"date\"].dt.year  # Extract year\n",
    "fed_speech[\"month\"] = fed_speech[\"date\"].dt.month  # Extract month\n",
    "fed_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1746540238841,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "nqQ9fLnhkObx",
    "outputId": "2c1592c6-8c0d-4522-8bdf-4fceff48ee75"
   },
   "outputs": [],
   "source": [
    "fed_speech[(fed_speech.year == 2024) & (fed_speech.month == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1746540238854,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "QvWqQoYmqbMg"
   },
   "outputs": [],
   "source": [
    "## taking the most recent speech\n",
    "fixed_fed_speech = fed_speech[(fed_speech.year == 2024) & (fed_speech.month == 3)][\"text\"].values[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5QdEtqFLf9p"
   },
   "source": [
    "In this step, we preprocess the speech text by **tokenizing, removing stopwords, and eliminating punctuation** to prepare the data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "executionInfo": {
     "elapsed": 1204,
     "status": "ok",
     "timestamp": 1746540240059,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "3ULH2L5YqmBp",
    "outputId": "585e04e6-b276-4511-cca3-7a570eeeab4a"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenize text\n",
    "    table = str.maketrans('', '', string.punctuation)  # Create a table for removing punctuation\n",
    "    filtered_tokens = [\n",
    "        token.translate(table) for token in tokens\n",
    "        if token.isalnum() and token not in stop_words  # Remove stop words here!\n",
    "    ]\n",
    "    cleaned_text = ' '.join(filtered_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "fixed_fed_speech = clean_text(fixed_fed_speech)\n",
    "fixed_fed_speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QIp3-11L4Md"
   },
   "source": [
    "## Preparing Dataloader for multimodal model\n",
    "\n",
    "We create a **`Multimodal Dataset Class`**, integrating time-series data, static features, LiDAR images, and textual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "d96c934b132749eeb798beeb2b529c11",
      "c913915d23034203ac0499af68a92790",
      "2c9a308346834db7b03dafeef010af09",
      "6ff6b70b27ff483f941ce0d4a42ecbed",
      "42c7a9250ac84da9b4d211ceb1acce4d",
      "f2c30e557b9343a6978287de018a2beb",
      "c9343ba18c1543249f226868c69db7b4",
      "cbbe1b89156f48979c9c3c4e952a0925",
      "b5f7e422606d4f56a435360db6f99a0e",
      "da6753e58c79414ea1e42013c62a40a5",
      "25447e2c5bd64f5f8b1c6d923ed690dd",
      "215a3c5d5bdb4784adc45ccf3df35fdb",
      "2a16d068c051404b8734489b2d686b71",
      "750cc1d3e9ab47dfa230c6a683a0b92d",
      "5bb53b0e94da4d24bd2ded1a10a03403",
      "b21998e10af149629050ce6250ad173c",
      "60683ecfd8264ddca063a2277131c799",
      "d76c73994f9f41488588429487ffe4d4",
      "4557bc150a2d4bd6af1567be3166e2da",
      "134bed74b8dd4128bb7b3a22cb071308",
      "3233b5c442c94e95b6bd2eec9eb7d631",
      "34fe1862e48844d685f63e5e9a3182e7",
      "594d41ab15cc4d4b9ece5b1caf754d6b",
      "b8da5205e9f54f4086cb29c5c64acdb2",
      "ed5ca8e7e9504c5f83a1074dca74271b",
      "c2aed09c72084b74ae51ebed714f30a1",
      "cff087fab8ba4d11b462faceb874ae6d",
      "8846763b3fae4222b2eb5e6383cb7f3d",
      "b32bf767ba234504969c0f66360c7396",
      "1a7da2dc547b499e8e8ded2b126b28a8",
      "6200125d4de149c4b43d4e361c946a89",
      "de5e00cc94f34319abd0abc951977da2",
      "ba84966a992440a992ef2ee42413a298",
      "6693d324fef241e69e79c688009a4091",
      "011d26523e22424ca55cd3cde5f63649",
      "532511b13417401bb763d5b5ecdf7bb1",
      "1616750eb7ce4a988f9a675598020dbb",
      "3898838529d0456d9f9129479ed8231e",
      "abe1c7c438af4458b85bb58df87b2c1b",
      "e854e66c2ce0443c8714467eace81d9a",
      "345652fa327e4fae9df0c2b09a82420a",
      "d74054ef3bfe4fb0aacda8fdf4d9f58e",
      "9aae578c8fcb442aaf895254819f6b00",
      "26a52b5e28db40d081b011f4493b8682"
     ]
    },
    "executionInfo": {
     "elapsed": 1735,
     "status": "ok",
     "timestamp": 1746540241805,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "VBrdvVq3kZWx",
    "outputId": "ac773f6d-d9fd-453f-c021-38f9e9e1ab3b"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "fixed_tokens = tokenizer(fixed_fed_speech, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "fixed_tokens = {key: val.squeeze(0) for key, val in fixed_tokens.items()}  # Store as dict\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, dataframe, y_values):\n",
    "        \"\"\"\n",
    "        dataframe  : DataFrame containing time series, static variables, and LiDAR file paths\n",
    "        fixed_text : Single fixed text string (e.g., FED speech that applies to all)\n",
    "        tokenizer  : Transformer tokenizer for text processing\n",
    "        max_length : Max token length for text processing\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.y_values = torch.tensor(y_values, dtype=torch.float32)  # Ensure target is float32\n",
    "\n",
    "\n",
    "        # Define image transformation\n",
    "        self.normalize_transform = transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "\n",
    "\n",
    "        # Identify column indices for time-series and static variables\n",
    "        self.time_series_start = 0\n",
    "        self.time_series_end = 8\n",
    "        self.static_start = 8\n",
    "        self.static_end = -1\n",
    "\n",
    "\n",
    "        # Define image loading. We use CV2 for faster loading\n",
    "    def load_image(self, image_path):\n",
    "        \"\"\"Load and preprocess image using OpenCV for speed.\"\"\"\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "        image = cv2.resize(image, (224, 224))  # Resize\n",
    "        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0) / 255.0  # Normalize 0-1\n",
    "        return self.normalize_transform(image)\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "\n",
    "        #  Ensure time-series to tensor\n",
    "        time_series = torch.tensor(\n",
    "            np.array(row.iloc[self.time_series_start:self.time_series_end].tolist()),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "\n",
    "\n",
    "        # Static variable to tensor\n",
    "        static_features = torch.tensor(\n",
    "            np.array(row.iloc[self.static_start:self.static_end].astype(float).values.tolist()),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        # Load LiDAR image (grayscale)\n",
    "        image = self.load_image(row[\"LiDAR_File\"])\n",
    "\n",
    "        # Expand fixed text tokens to match batch size\n",
    "        batch_text_tokens = fixed_tokens\n",
    "\n",
    "        # Retrieve target\n",
    "        target = self.y_values[idx]\n",
    "\n",
    "        # Return dictionary (use precomputed text for all samples)\n",
    "        return {\n",
    "            \"time_series\": time_series,\n",
    "            \"static_features\": static_features,\n",
    "            \"image_data\": image,\n",
    "            \"text_data\": batch_text_tokens,\n",
    "            \"target\": target\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7F1nM9F2M1Zj"
   },
   "source": [
    "This code splits the dataset, creates PyTorch dataset instances, and prepares data loaders for training, validation, and testing in a multimodal deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1746540241826,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "cpBE7Q2lfa88"
   },
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):\n",
    "    \"\"\"Ensure each worker has a different seed based on global seed.\"\"\"\n",
    "    seed = SEED + worker_id\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1067,
     "status": "ok",
     "timestamp": 1746540242901,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "Hdo0oILXoXkz",
    "outputId": "34fc5c00-6827-48d9-e56c-3290801fc4bb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-val split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.33, random_state=42, stratify=y_train_val)\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)  # For multi-GPU\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Create dataset instances (pass y_train & y_test separately)\n",
    "train_dataset = MultimodalDataset(x_train, y_train)\n",
    "val_dataset = MultimodalDataset(x_val, y_val)\n",
    "test_dataset = MultimodalDataset(x_test, y_test)\n",
    "\n",
    "# Create PyTorch DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2,\n",
    "                          worker_init_fn=worker_init_fn, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "# Check batch structure\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"Time-series data shape: {batch['time_series'].shape}\")  # (batch_size, num_features, seq_length)\n",
    "print(f\"Static feature shape: {batch['static_features'].shape}\")  # (batch_size, num_static_features)\n",
    "print(f\"Text input IDs shape: {batch['text_data']['input_ids'].shape}\")  # (batch_size, max_length)\n",
    "print(f\"Image data shape: {batch['image_data'].shape}\")  # (batch_size, 1, 256, 256)\n",
    "print(f\"Target shape: {batch['target'].shape}\")  # (batch_size,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcTh5nr3M8S_"
   },
   "source": [
    "## Multimodal deep learning model - intermediate fusion\n",
    "\n",
    "In this section, we will build a multimodal deep learning model that integrates four distinct data modalities:\n",
    "\n",
    "\n",
    "*   Time Series Data: Loan performance history over time with Transformer Encoder.\n",
    "*   Static Features: Borrower information, property details, and loan\n",
    "*   LiDAR Images: LiDAR images processed using a CNN.\n",
    "*   Textual Data: Federal Reserve speeches analyzed with DistilBERT.\n",
    "\n",
    "\n",
    "To predict whether a loan will become delinquent in the following quarter, we will utilize a combination of Transformers for time-series data, CNNs for image processing, and a fusion layer to integrate information from all modalities effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1746540242907,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "X4htAs97vSXl"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from transformers import DistilBertModel\n",
    "\n",
    "### Positional Encoding Module\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + 0.1 * self.pe[:, :x.size(1), :]\n",
    "\n",
    "### Time-Series Transformer Encoder with Positional Encoding\n",
    "class TimeSeriesModel(nn.Module):\n",
    "    def __init__(self, num_time_series_features, seq_length, dropout=0.1):\n",
    "        super(TimeSeriesModel, self).__init__()\n",
    "\n",
    "        self.proj = nn.Linear(num_time_series_features, 64)\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim=64, max_len=seq_length)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=4, dim_feedforward=128, dropout=dropout, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(seq_length * 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.proj(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "### CNN Model for LiDAR Images (BatchNorm + Dropout)\n",
    "class LiDARCNN(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super(LiDARCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 56 * 56, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "### Multimodal Model\n",
    "class MultimodalDelinquencyModel(nn.Module):\n",
    "    def __init__(self, num_time_series_features, seq_length, num_static_features, dropout=0.3):\n",
    "        super(MultimodalDelinquencyModel, self).__init__()\n",
    "\n",
    "        ### Time-Series Component (Transformer-Based with Positional Encoding)\n",
    "        self.time_series_model = TimeSeriesModel(num_time_series_features, seq_length, dropout)\n",
    "\n",
    "        ### Static Features Component (MLP)\n",
    "        self.static_fc = nn.Sequential(\n",
    "            nn.Linear(num_static_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        ### Text Component (DistilBERT)\n",
    "        self.text_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.text_fc = nn.Sequential(\n",
    "            nn.Linear(self.text_model.config.hidden_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        ### LiDAR Image Component (CNN)\n",
    "        self.image_model = LiDARCNN(dropout)\n",
    "\n",
    "        ### Fusion Layer\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(128 + 128 + 128 + 128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, time_series, static_features, text_inputs, image_data):\n",
    "        ### Time-Series Processing\n",
    "        time_series_out = self.time_series_model(time_series)\n",
    "\n",
    "        ### Static Feature Processing\n",
    "        static_out = self.static_fc(static_features)\n",
    "\n",
    "        ### Text Processing (DistilBERT)\n",
    "        text_out = self.text_model(**text_inputs).last_hidden_state[:, 0, :]\n",
    "        text_out = self.text_fc(text_out)\n",
    "\n",
    "        ### LiDAR Image Processing (CNN)\n",
    "        image_out = self.image_model(image_data)\n",
    "\n",
    "        ### Fusion\n",
    "        fused = torch.cat([time_series_out, static_out, text_out, image_out], dim=1)\n",
    "        output = self.fusion_layer(fused)\n",
    "\n",
    "        return output  # Raw logits (for BCEWithLogitsLoss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHxys2JzN8Jx"
   },
   "source": [
    "Now, let's begin training our multimodal deep learning model! Given its complexity, training may take some time.  \n",
    "\n",
    "To improve efficiency, we are leveraging **mixed precision training** with `torch.amp.GradScaler`, which accelerates computations while reducing memory consumption.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379,
     "referenced_widgets": [
      "16e2a7bc45f4494e9883d6241907c973",
      "b249b937b903443cb01bbc6328d8ef96",
      "8d22feab1d924718b98318a9ede75520",
      "73cebbf34ccd4704a7887b15131e15b5",
      "fcac4be4788a45368dc8c669a77ebcfa",
      "4d29b1f5a7d04d5c9ceefd210f4b76be",
      "d22a94bf2b564ee381320af171fbf9d7",
      "964e3c5042c440d0af5f0b747317bc94",
      "971847be83ea44a98d0ba40d7eb7f82b",
      "ec452f1e5b83446baf2211cd9ca83567",
      "bb1ef9477f31411ea48e6229dcaffc37"
     ]
    },
    "executionInfo": {
     "elapsed": 2768611,
     "status": "ok",
     "timestamp": 1746543011521,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "SZc3R23exNkm",
    "outputId": "ae4f8c2a-d242-4c24-f3a4-a5bca4c47fcd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)  # For multi-GPU\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "num_time_series_features = 8\n",
    "seq_length = len(x_train.iloc[0, 0])  # Adjust based on your time-series length\n",
    "num_static_features = len(x_train.iloc[0, 8:-1])  # Adjust based on your dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultimodalDelinquencyModel(num_time_series_features, seq_length, num_static_features, dropout=0.3).to(device)\n",
    "\n",
    "# Loss function & optimizer\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight).to(device)  # Using BCEWithLogitsLoss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Mixed Precision Training (AMP)\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "# Best validation loss tracking\n",
    "best_val_loss = float(\"inf\")\n",
    "checkpoint_path = \"best_multimodal_model.pth\"\n",
    "\n",
    "\n",
    "### Training Function with Validation\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    global best_val_loss\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_train_loss = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        ### Training Loop\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Move data to GPU\n",
    "            time_series = batch[\"time_series\"].to(device)\n",
    "            static_features = batch[\"static_features\"].to(device)\n",
    "            image_data = batch[\"image_data\"].to(device)\n",
    "            text_inputs = {key: val.to(device) for key, val in batch[\"text_data\"].items()}\n",
    "            targets = batch[\"target\"].to(device)\n",
    "\n",
    "            with torch.amp.autocast('cuda'):  # Mixed Precision Training\n",
    "                outputs = model(time_series, static_features, text_inputs, image_data).squeeze()\n",
    "                loss = criterion(outputs, targets.float())\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_train_loss += loss.detach()  # Reduce unnecessary GPU sync\n",
    "\n",
    "            # Convert logits to probabilities for accuracy calculation\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predictions = (probs > 0.5).float()\n",
    "            total_correct += (predictions == targets).sum()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "        train_acc = 100 * total_correct.cpu().item() / total_samples\n",
    "        avg_train_loss = total_train_loss.item() / len(train_loader)\n",
    "\n",
    "        ### Validation Loop\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                time_series = batch[\"time_series\"].to(device)\n",
    "                static_features = batch[\"static_features\"].to(device)\n",
    "                image_data = batch[\"image_data\"].to(device)\n",
    "                text_inputs = {key: val.to(device) for key, val in batch[\"text_data\"].items()}\n",
    "                targets = batch[\"target\"].to(device)\n",
    "\n",
    "                outputs = model(time_series, static_features, text_inputs, image_data).squeeze()\n",
    "                loss = criterion(outputs, targets.float())\n",
    "                total_val_loss += loss.detach()\n",
    "\n",
    "                # Convert logits to probabilities for accuracy calculation\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                predictions = (probs > 0.5).float()\n",
    "                correct += (predictions == targets).sum()\n",
    "                total += targets.size(0)\n",
    "\n",
    "        val_acc = 100 * correct.cpu().item() / total\n",
    "        avg_val_loss = total_val_loss.item() / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        ### Save best model checkpoint\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"Best model saved at epoch {epoch+1} with val loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    print(\"Training Complete!\")\n",
    "\n",
    "### One epoch takes 1.5 min with A100\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIocY_7ys_-Q"
   },
   "source": [
    "Training takes approximately **15 minutes**. However, we observe that further training may be beneficial, as the validation loss continues to decrease.\n",
    "\n",
    "\n",
    "Now, let's proceed with evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1746543011546,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "i5B6zysX_jtp"
   },
   "outputs": [],
   "source": [
    "### Model Evaluation Function\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model and plots the confusion matrix (normalized) and ROC curve.\n",
    "\n",
    "    Args:\n",
    "        model: Trained PyTorch model.\n",
    "        test_loader: DataLoader with test samples.\n",
    "        device: Device (cuda or cpu).\n",
    "\n",
    "    Returns:\n",
    "        all_labels, all_preds, all_probs\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            # Move data to device\n",
    "            time_series = batch[\"time_series\"].to(device)\n",
    "            static_features = batch[\"static_features\"].to(device)\n",
    "            text_inputs = {key: val.to(device) for key, val in batch[\"text_data\"].items()}\n",
    "            image_data = batch[\"image_data\"].to(device)\n",
    "            targets = batch[\"target\"].to(device)\n",
    "\n",
    "            # Forward pass (raw logits)\n",
    "            logits = model(time_series, static_features, text_inputs, image_data).squeeze()\n",
    "\n",
    "            # Convert logits to probabilities using Sigmoid\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "            # Store results\n",
    "            all_probs.extend(probs)\n",
    "            all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    # Compute binary predictions based on threshold 0.5\n",
    "    all_preds = (all_probs >= 0.5).astype(int)\n",
    "\n",
    "    return all_labels, all_preds, all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74864,
     "status": "ok",
     "timestamp": 1746543086412,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "Kc_ji5lk-h2e",
    "outputId": "c3a9ba17-cdac-4746-b1a9-4057d4e19458"
   },
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load(checkpoint_path, weights_only=True))\n",
    "print(\"Loaded best model for evaluation!\")\n",
    "\n",
    "# Evaluate on test data\n",
    "all_labels, all_preds, all_probs = evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGFUlvcvtLm4"
   },
   "source": [
    "Our model performs pretty well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1746543652020,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "KnvoLGmT_E_O",
    "outputId": "0f80ba6d-8c7e-4a1c-cc62-183ad1e0c8ee"
   },
   "outputs": [],
   "source": [
    "### Confusion Matrix (Normalized)\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "cm_rates = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_rates, annot=True, fmt=\".2f\", cmap=sns.light_palette(\"seagreen\", as_cmap=True),\n",
    "                xticklabels=[\"No Delinquency\", \"Delinquent\"],\n",
    "                yticklabels=[\"No Delinquency\", \"Delinquent\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Normalized Confusion Matrix (Rates)\")\n",
    "plt.savefig(os.path.join(bookPath, \"multimodal_confusion_matrix.pdf\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1746543798247,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "RlRaZVYz_Nnr",
    "outputId": "36ff4c20-4162-4957-cad5-e7a1a9802cb5"
   },
   "outputs": [],
   "source": [
    "### ROC Curve & AUC Score\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "auc_score = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc_score:.3f})\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")  # Diagonal reference line\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"ROC Curve - Delinquency Prediction\")\n",
    "plt.legend(loc=4)\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join(bookPath, \"multimodal_roc_curves.pdf\"))\n",
    "plt.show()\n",
    "\n",
    "### Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(all_labels, all_preds, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AEsZ432WnmY"
   },
   "source": [
    "## Multimodal model with cross-attention\n",
    "\n",
    "In this section, we implement a multimodal deep learning model that integrates information from multiple data sources using cross-attention mechanisms. Unlike traditional models that process different modalities independently, cross-attention allows the model to dynamically learn relationships between feature representations, improving predictive performance.\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "Our model processes four distinct modalities:\n",
    "\n",
    "*  Time-Series Data: Loan performance over time, modeled using a Transformer with positional encoding.\n",
    "*  Static Features: Borrower and loan characteristics, processed through a Multi-Layer Perceptron (MLP).\n",
    "*  Text Data: Federal Reserve speeches, encoded using DistilBERT.\n",
    "*  LiDAR Images: Spatial features extracted via a CNN.\n",
    "\n",
    "\n",
    "To enhance feature interactions, cross-attention is applied at multiple levels:\n",
    "\n",
    "*  Text ↔ Time-Series: Captures relationships between Federal Reserve statements and historical loan performance.\n",
    "*  Static Features ↔ LiDAR Images: Links borrower characteristics with geographic-based insights.\n",
    "*  Time-Series ↔ Static Features: Models how borrower attributes influence loan behavior over time.\n",
    "\n",
    "### Fusion Strategy\n",
    "\n",
    "After applying cross-attention, the model undergoes two levels of feature refinement:\n",
    "\n",
    "*  Second-Level Cross-Attention: Further interactions between attended representations from different modalities.\n",
    "*  Weighted Fusion Mechanism: A learnable attention-based fusion layer assigns adaptive importance to each attended feature representation before making a final prediction.\n",
    "*  The fused representation is then passed through a fully connected prediction layer to estimate loan delinquency status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1746543822031,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "1FevJ78D6z7D"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel\n",
    "import math\n",
    "\n",
    "### Cross-Attention Module\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads=4, dropout=0.1):\n",
    "        super(CrossAttention, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, dropout=dropout)\n",
    "        self.gate = nn.Linear(embed_dim * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.scale = nn.Parameter(torch.ones(1))  # Learnable scaling factor\n",
    "        self.norm = nn.LayerNorm(embed_dim)  # Layer normalization\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Cross-Attention between two modalities.\n",
    "        Args:\n",
    "            x1 (tensor): Query features (batch, feature_dim).\n",
    "            x2 (tensor): Key and Value features (batch, feature_dim).\n",
    "        Returns:\n",
    "            tensor: Attended feature representation.\n",
    "        \"\"\"\n",
    "        gate_value = self.sigmoid(self.gate(torch.cat([x1, x2], dim=-1)))  # Compute gate\n",
    "        attn_output, _ = self.attention(x1.unsqueeze(0), x2.unsqueeze(0), x2.unsqueeze(0))\n",
    "        return self.norm(self.scale * (gate_value * attn_output.squeeze(0) + (1 - gate_value) * x1))\n",
    "\n",
    "\n",
    "### Positional Encoding Module\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # Create a positional encoding matrix (max_len, embed_dim)\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # Compute sine and cosine functions for even/odd indices\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # Sin for even indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # Cos for odd indices\n",
    "\n",
    "        pe = pe.unsqueeze(0)  # Add batch dimension\n",
    "        self.register_buffer('pe', pe)  # Store as a buffer (not trainable)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (tensor): Shape (batch, seq_len, embed_dim)\n",
    "        Returns:\n",
    "            tensor: Positionally encoded input\n",
    "        \"\"\"\n",
    "        return x + 0.1 * self.pe[:, :x.size(1), :]\n",
    "\n",
    "\n",
    "### Time-Series Transformer Encoder with Positional Encoding\n",
    "class TimeSeriesModel(nn.Module):\n",
    "    def __init__(self, num_time_series_features, seq_length, dropout=0.1):\n",
    "        super(TimeSeriesModel, self).__init__()\n",
    "\n",
    "        # Projection Layer (Linear transformation for input features)\n",
    "        self.proj = nn.Linear(num_time_series_features, 64)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.positional_encoding = PositionalEncoding(embed_dim=64, max_len=seq_length)\n",
    "\n",
    "        # Transformer Encoder Layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=4, dim_feedforward=128, dropout=dropout, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "\n",
    "        # Fully Connected Output Layer\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(seq_length * 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # Change shape to (batch, seq_len, num_features)\n",
    "        x = self.proj(x)  # Project input features to embedding space\n",
    "        x = self.positional_encoding(x)  # Add positional encoding\n",
    "        x = self.transformer(x)  # Pass through Transformer Encoder\n",
    "        x = x.reshape(x.shape[0], -1)  # Flatten for fully connected layer\n",
    "        return self.fc(x)  # Fully Connected Output\n",
    "\n",
    "### Static Feature Model with Dropout\n",
    "class StaticModel(nn.Module):\n",
    "    def __init__(self, num_static_features, dropout=0.3):\n",
    "        super(StaticModel, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_static_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "### Text Model (DistilBERT) with Dropout\n",
    "class TextModel(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super(TextModel, self).__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.bert.config.hidden_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, text_inputs):\n",
    "        text_out = self.bert(**text_inputs).last_hidden_state[:, 0, :]\n",
    "        return self.fc(text_out)\n",
    "\n",
    "### CNN Model for LiDAR Images (BatchNorm + Dropout)\n",
    "class LiDARCNN(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super(LiDARCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 56 * 56, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return self.fc(x)\n",
    "\n",
    "### Final Multimodal Model with Cross-Attention\n",
    "class CrossAttentionFusionModel(nn.Module):\n",
    "    def __init__(self, num_time_series_features, seq_length, num_static_features, dropout=0.3):\n",
    "        super(CrossAttentionFusionModel, self).__init__()\n",
    "\n",
    "        self.time_series_model = TimeSeriesModel(num_time_series_features, seq_length, dropout)\n",
    "        self.static_model = StaticModel(num_static_features, dropout)\n",
    "        self.text_model = TextModel(dropout)\n",
    "        self.image_model = LiDARCNN(dropout)\n",
    "\n",
    "        # Cross-Attention Layers\n",
    "        self.attn_text_time = CrossAttention(embed_dim=128, num_heads=4, dropout=dropout)  # Text <-> Time-Series\n",
    "        self.attn_static_image = CrossAttention(embed_dim=128, num_heads=4, dropout=dropout)  # Static <-> Image\n",
    "        self.attn_time_static = CrossAttention(embed_dim=128, num_heads=4, dropout=dropout)  # Time-Series <-> Static\n",
    "\n",
    "        # Second-Level Cross-Attention\n",
    "        self.attn_fusion1 = CrossAttention(embed_dim=128, num_heads=4, dropout=dropout)  # Between attended_text_time and attended_static_image\n",
    "        self.attn_fusion2 = CrossAttention(embed_dim=128, num_heads=4, dropout=dropout)  # Between attended_time_static and attended_static_image\n",
    "\n",
    "\n",
    "\n",
    "        # Learnable Attention-Based Fusion Weights\n",
    "        self.attn_weights = nn.Linear(128 * 3, 3)\n",
    "\n",
    "        # Final Fusion Layer\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, time_series, static_features, text_inputs, image_data):\n",
    "        time_series_out = self.time_series_model(time_series)\n",
    "        static_out = self.static_model(static_features)\n",
    "        text_out = self.text_model(text_inputs)\n",
    "        image_out = self.image_model(image_data)\n",
    "\n",
    "        # Apply cross-attention (Text ↔ Time-Series, Static ↔ Image, Time-Series ↔ Static)\n",
    "        attended_text_time = self.attn_text_time(text_out, time_series_out)\n",
    "        attended_static_image = self.attn_static_image(static_out, image_out)\n",
    "        attended_time_static = self.attn_time_static(time_series_out, static_out)\n",
    "\n",
    "        # Apply second-level cross-attention for deeper interaction\n",
    "        attended_fusion1 = self.attn_fusion1(attended_text_time, attended_static_image)\n",
    "        attended_fusion2 = self.attn_fusion2(attended_time_static, attended_static_image)\n",
    "\n",
    "        # Weighted Fusion\n",
    "        weights = torch.softmax(self.attn_weights(torch.cat([attended_fusion1, attended_fusion2, attended_static_image], dim=1)), dim=1)\n",
    "        fused_weighted = (weights[:, 0].unsqueeze(1) * attended_fusion1 +\n",
    "                          weights[:, 1].unsqueeze(1) * attended_fusion2 +\n",
    "                          weights[:, 2].unsqueeze(1) * attended_static_image)\n",
    "\n",
    "        return self.fusion_layer(fused_weighted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1746543824047,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "c3_QdCuLASYa",
    "outputId": "78da4057-d150-4f13-cff7-2e304e161a09"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del model\n",
    "del optimizer\n",
    "del train_loader\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.reset_max_memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2762929,
     "status": "ok",
     "timestamp": 1746546605666,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "q26xUl_S74lX",
    "outputId": "c480ecf0-1dc5-47b0-8a40-191d47c79956"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)  # For multi-GPU\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Create PyTorch DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2,\n",
    "                          worker_init_fn=worker_init_fn, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "# Initialize model\n",
    "num_time_series_features = 8\n",
    "seq_length = len(x_train.iloc[0, 0])  # Adjust based on your time-series length\n",
    "num_static_features = len(x_train.iloc[0, 8:-1])  # Adjust based on your dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CrossAttentionFusionModel(num_time_series_features, seq_length, num_static_features, dropout=0.3).to(device)\n",
    "\n",
    "# Loss function & optimizer\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight).to(device)  # Using BCEWithLogitsLoss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Best validation loss tracking\n",
    "best_val_loss = float(\"inf\")\n",
    "checkpoint_path = \"best_multimodal_cross_attention_model.pth\"\n",
    "\n",
    "# takes 1.5 min per epoch with A100\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75191,
     "status": "ok",
     "timestamp": 1746546680866,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "HfOkReUmAjB0",
    "outputId": "a85b72af-cbdf-4213-fd1e-43344a23f7ca"
   },
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load(checkpoint_path, weights_only=True))\n",
    "print(\"Loaded best model for evaluation!\")\n",
    "\n",
    "# Evaluate on test data\n",
    "all_labels, all_preds, all_probs = evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1746546730635,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "iE5bouhdAoSE",
    "outputId": "d5456331-fc2e-47b8-a8d0-86481a810b03"
   },
   "outputs": [],
   "source": [
    "### Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "cm_rates = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_rates, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "                xticklabels=[\"No Delinquency\", \"Delinquent\"],\n",
    "                yticklabels=[\"No Delinquency\", \"Delinquent\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Normalized Confusion Matrix (Rates)\")\n",
    "plt.savefig(os.path.join(bookPath, \"multimodal_confusion_matrix_crossattention.pdf\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1746546739461,
     "user": {
      "displayName": "Cristián Bravo",
      "userId": "07563968753594904197"
     },
     "user_tz": 240
    },
    "id": "RrFfCrIaAqP9",
    "outputId": "69e8fd71-2f0f-4d33-82e3-1ede80736fd2"
   },
   "outputs": [],
   "source": [
    "### ROC Curve & AUC Score\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "auc_score = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc_score:.3f})\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")  # Diagonal reference line\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"ROC Curve - Delinquency Prediction\")\n",
    "plt.legend(loc=4)\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join(bookPath, \"multimodal_roc_curve_crossattention.pdf\"))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(all_labels, all_preds, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N47L67_fyIPG"
   },
   "source": [
    "We observe an improvement in the ROC AUC score."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "011d26523e22424ca55cd3cde5f63649": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abe1c7c438af4458b85bb58df87b2c1b",
      "placeholder": "​",
      "style": "IPY_MODEL_e854e66c2ce0443c8714467eace81d9a",
      "value": "tokenizer.json: 100%"
     }
    },
    "134bed74b8dd4128bb7b3a22cb071308": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1616750eb7ce4a988f9a675598020dbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9aae578c8fcb442aaf895254819f6b00",
      "placeholder": "​",
      "style": "IPY_MODEL_26a52b5e28db40d081b011f4493b8682",
      "value": " 466k/466k [00:00&lt;00:00, 6.29MB/s]"
     }
    },
    "16e2a7bc45f4494e9883d6241907c973": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b249b937b903443cb01bbc6328d8ef96",
       "IPY_MODEL_8d22feab1d924718b98318a9ede75520",
       "IPY_MODEL_73cebbf34ccd4704a7887b15131e15b5"
      ],
      "layout": "IPY_MODEL_fcac4be4788a45368dc8c669a77ebcfa"
     }
    },
    "1a7da2dc547b499e8e8ded2b126b28a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "215a3c5d5bdb4784adc45ccf3df35fdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2a16d068c051404b8734489b2d686b71",
       "IPY_MODEL_750cc1d3e9ab47dfa230c6a683a0b92d",
       "IPY_MODEL_5bb53b0e94da4d24bd2ded1a10a03403"
      ],
      "layout": "IPY_MODEL_b21998e10af149629050ce6250ad173c"
     }
    },
    "25447e2c5bd64f5f8b1c6d923ed690dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26a52b5e28db40d081b011f4493b8682": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a16d068c051404b8734489b2d686b71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60683ecfd8264ddca063a2277131c799",
      "placeholder": "​",
      "style": "IPY_MODEL_d76c73994f9f41488588429487ffe4d4",
      "value": "config.json: 100%"
     }
    },
    "2c9a308346834db7b03dafeef010af09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbbe1b89156f48979c9c3c4e952a0925",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b5f7e422606d4f56a435360db6f99a0e",
      "value": 48
     }
    },
    "3233b5c442c94e95b6bd2eec9eb7d631": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "345652fa327e4fae9df0c2b09a82420a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34fe1862e48844d685f63e5e9a3182e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3898838529d0456d9f9129479ed8231e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42c7a9250ac84da9b4d211ceb1acce4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4557bc150a2d4bd6af1567be3166e2da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d29b1f5a7d04d5c9ceefd210f4b76be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "532511b13417401bb763d5b5ecdf7bb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_345652fa327e4fae9df0c2b09a82420a",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d74054ef3bfe4fb0aacda8fdf4d9f58e",
      "value": 466062
     }
    },
    "594d41ab15cc4d4b9ece5b1caf754d6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b8da5205e9f54f4086cb29c5c64acdb2",
       "IPY_MODEL_ed5ca8e7e9504c5f83a1074dca74271b",
       "IPY_MODEL_c2aed09c72084b74ae51ebed714f30a1"
      ],
      "layout": "IPY_MODEL_cff087fab8ba4d11b462faceb874ae6d"
     }
    },
    "5bb53b0e94da4d24bd2ded1a10a03403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3233b5c442c94e95b6bd2eec9eb7d631",
      "placeholder": "​",
      "style": "IPY_MODEL_34fe1862e48844d685f63e5e9a3182e7",
      "value": " 483/483 [00:00&lt;00:00, 57.1kB/s]"
     }
    },
    "60683ecfd8264ddca063a2277131c799": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6200125d4de149c4b43d4e361c946a89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6693d324fef241e69e79c688009a4091": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_011d26523e22424ca55cd3cde5f63649",
       "IPY_MODEL_532511b13417401bb763d5b5ecdf7bb1",
       "IPY_MODEL_1616750eb7ce4a988f9a675598020dbb"
      ],
      "layout": "IPY_MODEL_3898838529d0456d9f9129479ed8231e"
     }
    },
    "6ff6b70b27ff483f941ce0d4a42ecbed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da6753e58c79414ea1e42013c62a40a5",
      "placeholder": "​",
      "style": "IPY_MODEL_25447e2c5bd64f5f8b1c6d923ed690dd",
      "value": " 48.0/48.0 [00:00&lt;00:00, 5.73kB/s]"
     }
    },
    "73cebbf34ccd4704a7887b15131e15b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec452f1e5b83446baf2211cd9ca83567",
      "placeholder": "​",
      "style": "IPY_MODEL_bb1ef9477f31411ea48e6229dcaffc37",
      "value": " 268M/268M [00:01&lt;00:00, 336MB/s]"
     }
    },
    "750cc1d3e9ab47dfa230c6a683a0b92d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4557bc150a2d4bd6af1567be3166e2da",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_134bed74b8dd4128bb7b3a22cb071308",
      "value": 483
     }
    },
    "8846763b3fae4222b2eb5e6383cb7f3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d22feab1d924718b98318a9ede75520": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_964e3c5042c440d0af5f0b747317bc94",
      "max": 267954768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_971847be83ea44a98d0ba40d7eb7f82b",
      "value": 267954768
     }
    },
    "964e3c5042c440d0af5f0b747317bc94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "971847be83ea44a98d0ba40d7eb7f82b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9aae578c8fcb442aaf895254819f6b00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abe1c7c438af4458b85bb58df87b2c1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b21998e10af149629050ce6250ad173c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b249b937b903443cb01bbc6328d8ef96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d29b1f5a7d04d5c9ceefd210f4b76be",
      "placeholder": "​",
      "style": "IPY_MODEL_d22a94bf2b564ee381320af171fbf9d7",
      "value": "model.safetensors: 100%"
     }
    },
    "b32bf767ba234504969c0f66360c7396": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5f7e422606d4f56a435360db6f99a0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b8da5205e9f54f4086cb29c5c64acdb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8846763b3fae4222b2eb5e6383cb7f3d",
      "placeholder": "​",
      "style": "IPY_MODEL_b32bf767ba234504969c0f66360c7396",
      "value": "vocab.txt: 100%"
     }
    },
    "ba84966a992440a992ef2ee42413a298": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb1ef9477f31411ea48e6229dcaffc37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2aed09c72084b74ae51ebed714f30a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de5e00cc94f34319abd0abc951977da2",
      "placeholder": "​",
      "style": "IPY_MODEL_ba84966a992440a992ef2ee42413a298",
      "value": " 232k/232k [00:00&lt;00:00, 4.61MB/s]"
     }
    },
    "c913915d23034203ac0499af68a92790": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2c30e557b9343a6978287de018a2beb",
      "placeholder": "​",
      "style": "IPY_MODEL_c9343ba18c1543249f226868c69db7b4",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "c9343ba18c1543249f226868c69db7b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbbe1b89156f48979c9c3c4e952a0925": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cff087fab8ba4d11b462faceb874ae6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d22a94bf2b564ee381320af171fbf9d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d74054ef3bfe4fb0aacda8fdf4d9f58e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d76c73994f9f41488588429487ffe4d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d96c934b132749eeb798beeb2b529c11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c913915d23034203ac0499af68a92790",
       "IPY_MODEL_2c9a308346834db7b03dafeef010af09",
       "IPY_MODEL_6ff6b70b27ff483f941ce0d4a42ecbed"
      ],
      "layout": "IPY_MODEL_42c7a9250ac84da9b4d211ceb1acce4d"
     }
    },
    "da6753e58c79414ea1e42013c62a40a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de5e00cc94f34319abd0abc951977da2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e854e66c2ce0443c8714467eace81d9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec452f1e5b83446baf2211cd9ca83567": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed5ca8e7e9504c5f83a1074dca74271b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a7da2dc547b499e8e8ded2b126b28a8",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6200125d4de149c4b43d4e361c946a89",
      "value": 231508
     }
    },
    "f2c30e557b9343a6978287de018a2beb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcac4be4788a45368dc8c669a77ebcfa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
